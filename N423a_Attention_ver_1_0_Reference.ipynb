{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysooch0819/AI16-Projects/blob/main/N423a_Attention_ver_1_0_Reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 2 / NOTE 3 - assignmnet*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N423. Seq2Seq with Attention Mechanism Assignment Plus"
      ],
      "metadata": {
        "id": "BQmqm0UB5jAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 시간에는 Korpora의 한국어 문답 데이터를 사용하여  \n",
        "**어텐션 매커니즘이 적용된 Seq2Seq 모델**을 이용해 한국어 챗봇을 제작해보겠습니다.  \n",
        "\n",
        "출처 : https://github.com/ko-nlp/Korpora  "
      ],
      "metadata": {
        "id": "2RPZjqlP5mBW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX9uvV60M6ze"
      },
      "source": [
        "#### **1) 데이터 로드 및 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AI-RgfUpM6zc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hq-XSpZJM6zf",
        "outputId": "ff9d6643-8d54-468b-9711-96febe5141c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('배 아프다', '약이 필요하면 도움을 받아보세요.'),\n",
              " ('배 터지겠네', '위를 좀 쉬게 해주세요.'),\n",
              " ('배 터지겠다.', '산책 좀 해야겠네여.'),\n",
              " ('배가 너무 고파', '뭐 좀 챙겨드세요.'),\n",
              " ('배가 넘넘 고파', '저도 밥 먹고 싶어요')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#현재 API를 사용하는 경우 pip 오류가 발생하므로 csv 형태의 Raw데이터를 그대로 가져와 사용하겠습니다.\n",
        "corpus = pd.read_csv('https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv')\n",
        "\n",
        "# 2,000개 데이터 사용 (Google Colab 일 경우 3,000개에서는 OOM 발생)\n",
        "texts = []\n",
        "pairs = []\n",
        "for i, (text, pair) in enumerate(zip(corpus['Q'], corpus['A'])):\n",
        "    texts.append(text)\n",
        "    pairs.append(pair)\n",
        "    if i >= 2000: \n",
        "        break \n",
        "\n",
        "# 데이터 체크\n",
        "list(zip(texts, pairs))[1995:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4_lC-m5XM6zg"
      },
      "outputs": [],
      "source": [
        "#regular expression(regex)를 사용\n",
        "import re\n",
        "\n",
        "def cleaning_sent(sentence):\n",
        "    '''\n",
        "    한글 및 숫자, 물음표 및 공백을 제외하고 제거하는 함수입니다.\n",
        "\n",
        "    Input:\n",
        "        sentence : str. 정제하려는 문장을 입력으로 받습니다.\n",
        "    Return:\n",
        "        정제 완료된 문장 반환. str\n",
        "    '''\n",
        "    sent = re.sub(r'[^1-9가-힣? ]', '', sentence)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RP4ts9MM6zg"
      },
      "source": [
        "Konlpy에서는 한국어 품사를 태그해주는 다양한 태거를 지원하고 있습니다.  \n",
        "이 중에서 이번에는 트위터에서 제작한 오픈소스 한국어 처리기인 Okt를 활용하도록 하겠습니다.  \n",
        "\n",
        "Konlpy 형태소 분석 및 품사 태깅 공식 문서 : https://konlpy.org/ko/v0.6.0/morph/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rgazCObrM6zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777f968c-af91-4711-ebc3-56ca053ae02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HeGBZSZvM6zh"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "def morpheme_anlysis(sentence):\n",
        "    '''\n",
        "    문장이 들어왔을 때, 형태소 단위로 분석해주는 함수입니다.\n",
        "    Input:\n",
        "        sentence : str. 형태소 분석을 하려는 문장입니다.\n",
        "    Return:\n",
        "        형태소 단위로 뛰워쓰기 되어있는 문장 반환. str\n",
        "    '''\n",
        "    return ' '.join(okt.morphs(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Omhm78RuM6zi"
      },
      "outputs": [],
      "source": [
        "def clean_and_morph(sentence, is_question=True):\n",
        "    '''\n",
        "    문장이 질문인지 대답인지에 맞추어 알맞은 형태로 변형해주는 함수입니다.\n",
        "\n",
        "    Input:\n",
        "        sentence : str. 변형하려는 문장입니다.\n",
        "        is_question : 문장이 질문인지, 대답인지 알려주는 값입니다. 문장이면 True, 대답이면 False를 받습니다.\n",
        "\n",
        "    Return:\n",
        "        문장 타입에 따라 알맞게 변형된 문장을 반환합니다.\n",
        "    '''\n",
        "\n",
        "    sentence = cleaning_sent(sentence)\n",
        "    sentence = morpheme_anlysis(sentence)\n",
        "\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        return ('<sos> ' + sentence, sentence + ' <eos>')\n",
        "\n",
        "def preprocessing(questions, pairs):\n",
        "    '''\n",
        "    한국어 문답 데이터를 전처리하는 함수입니다.\n",
        "    정제, 형태소 분석, 모델의 인풋,아웃풋으로 사용할 수 있는 형태로 변환하는 과정을 포함하고 있습니다.\n",
        "\n",
        "    Input:\n",
        "        questions : list. 문답 데이터 중 질문으로 이루어진 리스트를 받습니다.\n",
        "        pairs : list. 문답 데이터 중 답변으로 이루어진 리스트를 받습니다.\n",
        "\n",
        "    Return:\n",
        "        질문, 인풋 형태의 문답, 아웃풋 형태의 문답\n",
        "    '''\n",
        "    answer_in = []\n",
        "    answer_out = []\n",
        "    \n",
        "    pre_questions = [clean_and_morph(question, is_question=True) for question in questions]\n",
        "\n",
        "    for pair in pairs:\n",
        "        in_pair, out_pair = clean_and_morph(pair, is_question=False)\n",
        "        answer_in.append(in_pair)\n",
        "        answer_out.append(out_pair)\n",
        "\n",
        "    return pre_questions, answer_in, answer_out\n",
        "\n",
        "questions, answer_in, answer_out = preprocessing(texts, pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cade1PKiM6zi"
      },
      "source": [
        "#### **2) 토큰화**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리가 완료된 데이터를 모델에 넣을 수 있는 형태로 토큰화합니다."
      ],
      "metadata": {
        "id": "goJLWhYzao3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "j1DHvU_HH-tC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "14KIuO60M6zi"
      },
      "outputs": [],
      "source": [
        "#토크나이저 학습을 위해 전체 데이터 리스트를 하나 생성\n",
        "all_sentence = questions + answer_in + answer_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H7hw1n9dM6zj"
      },
      "outputs": [],
      "source": [
        "#리스트를 사용하여 tokenizer 학습\n",
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(all_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r3-ouBOHM6zj"
      },
      "outputs": [],
      "source": [
        "#질문 답변 데이터 토큰화\n",
        "question_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
        "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pIIGac9TM6zj",
        "outputId": "f81d5616-22b0-4803-86ee-249037138704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12시 땡', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다']\n",
            "[[1758, 2493], [1609, 2494, 2495, 1610], [974, 1759, 1760, 213, 197, 106]]\n"
          ]
        }
      ],
      "source": [
        "#토큰화가 잘 적용되었는지 확인\n",
        "print(questions[:3])\n",
        "print(question_sequence[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yj3sIhhsM6zk",
        "outputId": "f4d06c7d-094e-4dd0-af02-cebad77397c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.228385807096452\n",
            "12\n",
            "5.888055972013993\n",
            "20\n",
            "5.888055972013993\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#문장 최대 토큰 수 계산\n",
        "#max_len은 모델이 생성할 수 있는 문장의 최대 길이도 되므로 고려해서 선정해야함\n",
        "def len_cal(sentences):\n",
        "    total_len = 0\n",
        "    count = 0\n",
        "    maxlen = 0\n",
        "\n",
        "    for i in sentences:\n",
        "        if maxlen < len(i):\n",
        "            maxlen = len(i)\n",
        "        total_len += len(i)\n",
        "        count += 1\n",
        "\n",
        "    print(total_len / count)\n",
        "    print(maxlen)\n",
        "\n",
        "len_cal(question_sequence)\n",
        "len_cal(answer_in_sequence)\n",
        "len_cal(answer_out_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FtkJ_aoHM6zk"
      },
      "outputs": [],
      "source": [
        "#패딩\n",
        "max_len = 20\n",
        "question_pad = pad_sequences(question_sequence,\n",
        "                             max_len,\n",
        "                             padding= 'post')\n",
        "answer_in_pad = pad_sequences(answer_in_sequence,\n",
        "                             max_len,\n",
        "                             padding= 'post')\n",
        "answer_out_pad = pad_sequences(answer_out_sequence,\n",
        "                             max_len,\n",
        "                             padding= 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HkrQjoZXM6zk",
        "outputId": "36ca5eef-2c06-4d25-f653-d252379e1ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2001, 20), (2001, 20), (2001, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#패딩 적용 확인\n",
        "question_pad.shape, answer_in_pad.shape, answer_out_pad.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtLPE1pYM6zk"
      },
      "source": [
        "#### **3) 모델 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras Functional API**를 통해 모델을 구현해보겠습니다.  \n",
        "\n",
        "1. 아래 설명을 잘 읽고 코드를 작성하여 모델을 완성해주세요!  \n",
        "2. 모델이 잘 학습된다면 모델의 성능을 올리는 여러가지 기법을 적용하여 봅시다.  \n",
        "\n",
        "    예시)\n",
        "    - Dropout\n",
        "    - Multiple LSTM Layer\n",
        "    - ..."
      ],
      "metadata": {
        "id": "Zn3YK_rebEE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8N0f9AcFM6zl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dropout, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cckJeEFIM6zl"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        '''\n",
        "        Seq2Seq의 인코더입니다.\n",
        "        \n",
        "        Args:\n",
        "            units (int) : 인코더 내부 lstm의 노드 수.\n",
        "            vocab_size (int) : 임베딩 행렬의 단어 수. 없는 단어가 있으면 oov가 발생할 수 있습니다.\n",
        "                -> 훈련하려는 문장의 단어는 모두 포함하고 있는 것이 좋다!\n",
        "            embedding_dim (int) : 임베딩 차원 수. 복잡할수록 좋을 수도 있고, 아닐 수도 있습니다. 차원이 크면 보통 표현력이 좋다. but 용량이 커져서 안좋을 수 있다.\n",
        "            time_steps (int) : 문장 토큰의 수. ex) 안녕하세요 조윤행입니다. -> 안녕하세요/ 조윤행/ 입니다/ -> 토큰 수 : 3개\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(vocab_size,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        # (attention) return_sequences=True 추가\n",
        "        self.lstm = LSTM(units, \n",
        "                         return_state=True, \n",
        "                         return_sequences=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x)\n",
        "        # (attention) x return 추가\n",
        "        return x, [hidden_state, cell_state]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "  def call(self, query, values):\n",
        "      #key와 value는 동일하므로 values 하나로 선언하고 사용합니다. transpose_b : v=values를 전치(transpose)해주기 위해 사용.\n",
        "      scores = tf.matmul(query, values, transpose_b=True) # 쿼리 키 내적하여 상관관계 계산 (query vector) x (key vector)^ T\n",
        "      distribution = tf.nn.softmax(scores/ scores.shape[-1]) # d_k로 나눠주고 softmax 취해서 소프트맥스 스코어 계산하기\n",
        "      context_vector = tf.matmul(distribution, values) # 스코어 x value vector\n",
        "      return context_vector"
      ],
      "metadata": {
        "id": "pD3GOFI7ZyXI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_hriGneSM6zl"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        '''\n",
        "        Seq2Seq의 디코더입니다.\n",
        "        \n",
        "        Args:\n",
        "            units (int) : 디코더 내부 lstm의 노드 수.\n",
        "            vocab_size (int) : 임베딩 행렬의 단어 수. 없는 단어가 있으면 oov가 발생할 수 있습니다.\n",
        "                -> 훈련하려는 문장의 단어는 모두 포함하고 있는 것이 좋다!\n",
        "            embedding_dim (int) : 임베딩 차원 수. 복잡할수록 좋을 수도 있고, 아닐 수도 있습니다. 차원이 크면 보통 표현력이 좋다. but 용량이 커져서 안좋을 수 있다.\n",
        "            time_steps (int) : 문장 토큰의 수. 디코더에서는 최대로 생성할 수 있는 문장의 길이가 됩니다.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(vocab_size,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.lstm = LSTM(units,\n",
        "                         return_state=True,\n",
        "                         return_sequences=True)\n",
        "        #(attention) 어텐션 추가\n",
        "        self.attention = Attention()\n",
        "        self.dense = Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, initial_state):\n",
        "        # (attention) encoder_inputs 추가\n",
        "        encoder_inputs, decoder_inputs = inputs\n",
        "        x = self.embedding(decoder_inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
        "        \n",
        "        # (attention) query_vector, attention_matrix 추가\n",
        "        # 이전 hidden_state의 값을 concat으로 만들어 query_vector를 생성합니다.        \n",
        "        query_vector = tf.concat([initial_state[0][:, tf.newaxis, :], \n",
        "                               x[:, :-1, :]], axis=1)        \n",
        "        # query_vector와 인코더에서 나온 출력 값들로 attention을 구합니다.\n",
        "        attention_matrix = self.attention(query_vector, encoder_inputs)\n",
        "        # 위에서 구한 attention_matrix와 decoder의 출력 값을 concat 합니다.\n",
        "        x = tf.concat([x, attention_matrix], axis=-1)\n",
        "\n",
        "        x = self.dense(x)\n",
        "        return x, hidden_state, cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Dg-X-u7fM6zl"
      },
      "outputs": [],
      "source": [
        "class Seq2seq_with_Attention(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
        "        \"\"\"\n",
        "        어텐션이 적용된 Seq2Seq 모델입니다. 인코더와 디코더를 선언합니다.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.time_steps = time_steps\n",
        "\n",
        "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        \"\"\"\n",
        "        선언한 인코더와 디코더를 하나로 연결하여 Seq2Sqe with Attention 파이프라인을 구현합니다.\n",
        "        \n",
        "        Args:\n",
        "            inputs : 문장의 단어 인덱스로 이루어진 데이터.\n",
        "            training : True인 경우 교사강요를 사용하여 디코더의 입력값에 정답을 넣어주며, False인 경우 디코더의 출력 데이터를 입력으로 넣어주게 됩니다.\n",
        "        \"\"\"\n",
        "        if training:\n",
        "            encoder_inputs, decoder_inputs = inputs\n",
        "            #(attention) 인코더가 context vector뿐만 아니라 모든 출력값을 만들도록 수정\n",
        "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
        "            #(attention) 디코더가 인코더의 모든 출력값을 받도록 수정\n",
        "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), context_vector)\n",
        "            return decoder_outputs\n",
        "        else:\n",
        "            #(attention) 인코더가 context vector뿐만 아니라 모든 출력값을 만들도록 수정\n",
        "            encoder_outputs, context_vector = self.encoder(inputs)\n",
        "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
        "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
        "\n",
        "            for i in tf.range(self.time_steps):\n",
        "                #디코더가 인코더의 모든 출력값을 받도록 수정\n",
        "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq),\n",
        "                                                                            context_vector)\n",
        "                decoder_output = tf.cast(tf.argmax(decoder_output, axis= -1),\n",
        "                                         dtype=tf.int32)\n",
        "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
        "                results = results.write(i, decoder_output)\n",
        "\n",
        "                if decoder_output == self.end_token:\n",
        "                    break\n",
        "\n",
        "                target_seq = decoder_output\n",
        "                context_vector = [decoder_hidden, decoder_cell]\n",
        "\n",
        "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48AfKdUoM6zm"
      },
      "source": [
        "#### **4) 모델 훈련**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jCdjTO17M6zm"
      },
      "outputs": [],
      "source": [
        "# 학습 파라미터\n",
        "# 하이퍼 파라미터 튜닝 시 참고하기 쉽도록 한 셀에 모아 작성하는 것이 좋습니다.\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 16\n",
        "EMBEDDING_DIM = 100\n",
        "TIME_STEPS = max_len\n",
        "START_TOKEN = tokenizer.word_index['<sos>']\n",
        "END_TOKEN = tokenizer.word_index['<eos>']\n",
        "\n",
        "UNITS = 128\n",
        "\n",
        "# padding을 포함하기위해 +1\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "DATA_LENGTH = len(questions)\n",
        "SAMPLE_SIZE = 5\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aO7CUdXuM6zm"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련을 위해 모델을 선언합니다.\n",
        "seq2seq = Seq2seq_with_Attention(UNITS,\n",
        "                  VOCAB_SIZE,\n",
        "                  EMBEDDING_DIM,\n",
        "                  TIME_STEPS,\n",
        "                  START_TOKEN,\n",
        "                  END_TOKEN)\n",
        "\n",
        "seq2seq.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Af1yz77OM6zn",
        "outputId": "9b230850-6fbd-4597-8c52-35d9b3de5273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - 12s 10ms/step - loss: 2.7715 - acc: 0.7028\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 1.7120 - acc: 0.7493\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.6010 - acc: 0.7601\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.5323 - acc: 0.7611\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.4812 - acc: 0.7650\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.4386 - acc: 0.7695\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.3974 - acc: 0.7725\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 1.3571 - acc: 0.7743\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 1.3141 - acc: 0.7765\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.2710 - acc: 0.7795\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.2280 - acc: 0.7835\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.1835 - acc: 0.7884\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.1364 - acc: 0.7934\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.0907 - acc: 0.7989\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.0447 - acc: 0.8046\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 1.0002 - acc: 0.8106\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.9585 - acc: 0.8157\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.9136 - acc: 0.8236\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.8729 - acc: 0.8298\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.8322 - acc: 0.8359\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.7950 - acc: 0.8430\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.7593 - acc: 0.8493\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.7199 - acc: 0.8576\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.6880 - acc: 0.8632\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.6544 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.6267 - acc: 0.8747\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.5974 - acc: 0.8815\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.5678 - acc: 0.8861\n",
            "Epoch 29/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.5437 - acc: 0.8932\n",
            "Epoch 30/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.5209 - acc: 0.8957\n",
            "Epoch 31/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4982 - acc: 0.8996\n",
            "Epoch 32/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4809 - acc: 0.9018\n",
            "Epoch 33/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4584 - acc: 0.9073\n",
            "Epoch 34/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4375 - acc: 0.9109\n",
            "Epoch 35/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4186 - acc: 0.9141\n",
            "Epoch 36/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.4021 - acc: 0.9172\n",
            "Epoch 37/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3834 - acc: 0.9204\n",
            "Epoch 38/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.3725 - acc: 0.9221\n",
            "Epoch 39/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3629 - acc: 0.9232\n",
            "Epoch 40/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3446 - acc: 0.9268\n",
            "Epoch 41/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3319 - acc: 0.9288\n",
            "Epoch 42/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3258 - acc: 0.9291\n",
            "Epoch 43/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.3131 - acc: 0.9318\n",
            "Epoch 44/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2984 - acc: 0.9336\n",
            "Epoch 45/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2868 - acc: 0.9362\n",
            "Epoch 46/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2763 - acc: 0.9378\n",
            "Epoch 47/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2683 - acc: 0.9395\n",
            "Epoch 48/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2599 - acc: 0.9399\n",
            "Epoch 49/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2503 - acc: 0.9420\n",
            "Epoch 50/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2416 - acc: 0.9433\n",
            "Epoch 51/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2315 - acc: 0.9457\n",
            "Epoch 52/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2387 - acc: 0.9435\n",
            "Epoch 53/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2199 - acc: 0.9475\n",
            "Epoch 54/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2095 - acc: 0.9483\n",
            "Epoch 55/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.2012 - acc: 0.9511\n",
            "Epoch 56/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1945 - acc: 0.9523\n",
            "Epoch 57/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.1884 - acc: 0.9524\n",
            "Epoch 58/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.1840 - acc: 0.9541\n",
            "Epoch 59/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1769 - acc: 0.9555\n",
            "Epoch 60/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1672 - acc: 0.9575\n",
            "Epoch 61/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1611 - acc: 0.9591\n",
            "Epoch 62/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1531 - acc: 0.9612\n",
            "Epoch 63/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1469 - acc: 0.9619\n",
            "Epoch 64/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1415 - acc: 0.9644\n",
            "Epoch 65/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.1365 - acc: 0.9645\n",
            "Epoch 66/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.1318 - acc: 0.9662\n",
            "Epoch 67/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1294 - acc: 0.9662\n",
            "Epoch 68/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1251 - acc: 0.9670\n",
            "Epoch 69/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1170 - acc: 0.9703\n",
            "Epoch 70/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1131 - acc: 0.9704\n",
            "Epoch 71/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1106 - acc: 0.9716\n",
            "Epoch 72/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1029 - acc: 0.9743\n",
            "Epoch 73/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.1006 - acc: 0.9746\n",
            "Epoch 74/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0940 - acc: 0.9767\n",
            "Epoch 75/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0944 - acc: 0.9756\n",
            "Epoch 76/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0850 - acc: 0.9788\n",
            "Epoch 77/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0790 - acc: 0.9810\n",
            "Epoch 78/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0773 - acc: 0.9816\n",
            "Epoch 79/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0744 - acc: 0.9816\n",
            "Epoch 80/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0710 - acc: 0.9826\n",
            "Epoch 81/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0673 - acc: 0.9838\n",
            "Epoch 82/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0658 - acc: 0.9842\n",
            "Epoch 83/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0661 - acc: 0.9843\n",
            "Epoch 84/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0631 - acc: 0.9851\n",
            "Epoch 85/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0574 - acc: 0.9863\n",
            "Epoch 86/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0586 - acc: 0.9864\n",
            "Epoch 87/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0522 - acc: 0.9880\n",
            "Epoch 88/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0488 - acc: 0.9896\n",
            "Epoch 89/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0466 - acc: 0.9899\n",
            "Epoch 90/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0486 - acc: 0.9895\n",
            "Epoch 91/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0481 - acc: 0.9897\n",
            "Epoch 92/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0413 - acc: 0.9913\n",
            "Epoch 93/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0373 - acc: 0.9923\n",
            "Epoch 94/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0341 - acc: 0.9935\n",
            "Epoch 95/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0320 - acc: 0.9940\n",
            "Epoch 96/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0305 - acc: 0.9944\n",
            "Epoch 97/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0295 - acc: 0.9942\n",
            "Epoch 98/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0289 - acc: 0.9944\n",
            "Epoch 99/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0265 - acc: 0.9954\n",
            "Epoch 100/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0297 - acc: 0.9941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bc010a970>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "seq2seq.fit([question_pad, answer_in_pad],\n",
        "            answer_out_pad,\n",
        "            epochs=100,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLI-TTPEM6zn"
      },
      "source": [
        "#### **5) 챗봇 구현**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aDef5tMsM6zn"
      },
      "outputs": [],
      "source": [
        "# 인덱스를 단어로 변환하는 함수\n",
        "def convert_index_to_text(indexs, end_token):\n",
        "\n",
        "    sentence = ''\n",
        "    \n",
        "    for index in indexs:\n",
        "        if index == end_token:\n",
        "            break;\n",
        "        if index > 0 and tokenizer.index_word[index] is not None:\n",
        "            sentence += tokenizer.index_word[index]\n",
        "        else:\n",
        "            sentence += ''\n",
        "        \n",
        "        sentence += ' '\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EJjDOi2pM6zn"
      },
      "outputs": [],
      "source": [
        "# 문장을 입력받으면 대답을 만들어내는 함수를 제작합니다.\n",
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    # 변환된 인덱스를 문장으로 변환\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gG8QaYLXM6zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b321a08-7c29-4b63-efb8-3e7b78e710e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대화를 입력하세요\n",
            "안녕?\n",
            "answer: 저 도 반가워요 \n",
            "대화를 입력하세요\n",
            "안녕\n",
            "answer: 저 도 즐거워요 \n",
            "대화를 입력하세요\n",
            "좋아\n",
            "answer: 저 도 요 \n",
            "대화를 입력하세요\n",
            "ㅎㅎ\n",
            "answer: 뭐라도 드세요 \n",
            "대화를 입력하세요\n",
            "밥먹었어?\n",
            "answer: 저 는 배터리 가 밥 이 예요 \n",
            "대화를 입력하세요\n",
            "천잰데\n",
            "answer: 제 가 더 천재 예요 \n",
            "대화를 입력하세요\n",
            "똑똑하구나\n",
            "answer: 저 도 즐거워요 \n",
            "대화를 입력하세요\n",
            "즐겁ㄷ다\n",
            "answer: 저 도 즐거워요 \n",
            "대화를 입력하세요\n",
            "좋아해\n",
            "answer: 새로운 스타일 에 도전 하는 것 도 좋아요 \n",
            "대화를 입력하세요\n",
            "맞아\n",
            "answer: 저 도 즐거워요 \n",
            "대화를 입력하세요\n",
            "q\n"
          ]
        }
      ],
      "source": [
        "# 챗봇에서 입력한 문장을 모델에 넣을 수 있는 형태로 변환하는 함수\n",
        "def question_to_input(sentence):\n",
        "    sentence = clean_and_morph(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_pad = pad_sequences(question_sequence, maxlen= max_len, truncating='post', padding='post')\n",
        "    return question_pad\n",
        "\n",
        "# 간단한 챗봇 구현 -> q를 누르면 종료됩니다.\n",
        "def run_chatbot(question):\n",
        "    question_inputs = question_to_input(question)\n",
        "    results = make_prediction(seq2seq, question_inputs)\n",
        "    results = convert_index_to_text(results, END_TOKEN)\n",
        "    return results\n",
        "\n",
        "while True:\n",
        "    user_input = input('대화를 입력하세요\\n')\n",
        "    if user_input =='q':\n",
        "        break\n",
        "    print('answer: {}'.format(run_chatbot(user_input)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "13th",
      "language": "python",
      "name": "13th"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qX9uvV60M6ze",
        "Cade1PKiM6zi"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}