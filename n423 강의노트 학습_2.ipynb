{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoxBVCHwuuIOyBzcxporcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysooch0819/AI16-Projects/blob/main/n423%20%EA%B0%95%EC%9D%98%EB%85%B8%ED%8A%B8%20%ED%95%99%EC%8A%B5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5eip7ZQZ3Sv",
        "outputId": "7c4cd5c2-0f95-4ae6-ccd9-a7e988e6453b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "dict1 = {'a':123, 'b':425, 'c':236, 'd':945}\n",
        "dict1['a']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "metadata": {
        "id": "JVH7YTb_aELU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file= os.path.dirname(path_to_zip)+'/spa-eng/spa.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw4rZN2_aTHH",
        "outputId": "cac116f0-3a09-4114-d88d-80ff65d2a669"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유니코드 파일을 아스키코드로 변환하는 함수\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                  if unicodedata.category(c) != 'Mn')\n",
        "  \n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "metadata": {
        "id": "ZJbGkcpFaiD6"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNhX2Y3FbgOu",
        "outputId": "37195b9f-8b22-4c47-ef39-0ea0d93d9f85"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "metadata": {
        "id": "uy6cER3rb-S7"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKpd0WBcX_6",
        "outputId": "b492a8b0-6604-4ef1-966f-560a675c0bde"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "metadata": {
        "id": "ZQNPJJJgc_G7"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개 언어이기 때문에, tokenizer 가 각각의 언어별로 따로 필요하다\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "metadata": {
        "id": "WAJPWhaJdSUy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load할 dataset의 개수를 30000으로 설정\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# target과 input의 최대 길이 구하기(문장 최대 길이)\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "metadata": {
        "id": "yGGb3QmDdsXa"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8:2 비율로 train-test split 진행\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 데이터 개수 뽑아보기\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvK6LNxXeJ7y",
        "outputId": "15d1c176-e21c-408a-83e6-8de56999170c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 24000 6000 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구조와 관련된 파라미터 설정\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "# tf.data.Dataset -> 텐서플로우에서 제공하는 Dataset 클래스입니다.\n",
        "# Dataset 클래스는 배치 구성, 데이터셋 셔플, 윈도우 구현, 변환 함수 적용 등 다양한 기능을 제공합니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Tif4lrkyennz"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 배치 뽑아보기\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go71is6ffKZy",
        "outputId": "90c333be-b103-4c60-a91f-9894713d6d14"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 구현\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # |x| = (batch_sz, seq_len)\n",
        "    x = self.embedding(x) # |x| = (batch_sz, seq_len, embedding_dim)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "JdgDjcyefUDR"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample input 을 통해 Encoder 레이어 결과값의 shape 확인\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWDT3j-gDS8",
        "outputId": "cf2eecd2-c25e-4a37-fc32-4ef0716c49e1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    # W1(query_with_time_axis) == (batch_size, 1, units)\n",
        "    # W2(values) == (batch_size, max_len, units)\n",
        "    # W1(query_with_time_axis) + W2(values) == (batch_size, max_len, units)\n",
        "    # V(tf.nn.tanh(W1(query_with_time_axis) + W2(values))) == (batch_size, max_len, 1)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1) # attention_weights == (batch_size, max_length, 1)\n",
        "\n",
        "    context_vector = attention_weights * values # context_vector == (batch_size, max_len, hidden_size)\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # context_vector == (batch_size, hidden_size)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "ktAZyzh-giza"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQVvFs_khPHY",
        "outputId": "8ecc6a3f-c812-44c5-877c-8dcb9ce7442b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 구현\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x == (batch_size, 1)\n",
        "    # hidden == (batch_size, hidden_size)\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    # context_vector == (batch_size, hidden_size)\n",
        "    # attention_weights == (batch_size, max_length, 1)\n",
        "\n",
        "    x = self.embedding(x) # x == (batch_size, 1, embedding_dim)\n",
        "\n",
        "    # tf.expand_dims(context_vector, 1) == (batch_size, 1, hidden_size)\n",
        "    # tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) == (batch_size, 1, embedding_dim+hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    # output == (batch_size, 1, hidden_size)\n",
        "    # state == (batch_size, hidden_size)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    \n",
        "    output = tf.reshape(output, (-1, output.shape[2])) # output  == (batch_size * 1, hidden_size)\n",
        "\n",
        "    x = self.fc(output) # x == (batch_size, vocab)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "MBYbdItQhj9B"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScG7e9xOika2",
        "outputId": "14e6f52f-b0f9-4899-e7e0-8fba7a9e139c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "2E3TFex_i4hp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teacher Forcing \n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "fOnEribajR0m"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9QVBw5TkQJX",
        "outputId": "694cbfec-3bb9-47e2-86c7-c8a00c1d2b72"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7352\n",
            "Epoch 1 Batch 100 Loss 2.2401\n",
            "Epoch 1 Batch 200 Loss 1.8022\n",
            "Epoch 1 Batch 300 Loss 1.6722\n",
            "Epoch 1 Loss 2.0298\n",
            "Time taken for 1 epoch 41.12794899940491 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5520\n",
            "Epoch 2 Batch 100 Loss 1.4099\n",
            "Epoch 2 Batch 200 Loss 1.2896\n",
            "Epoch 2 Batch 300 Loss 1.2842\n",
            "Epoch 2 Loss 1.3882\n",
            "Time taken for 1 epoch 28.16383695602417 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1685\n",
            "Epoch 3 Batch 100 Loss 1.0594\n",
            "Epoch 3 Batch 200 Loss 0.9321\n",
            "Epoch 3 Batch 300 Loss 0.9300\n",
            "Epoch 3 Loss 0.9840\n",
            "Time taken for 1 epoch 28.1028950214386 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7131\n",
            "Epoch 4 Batch 100 Loss 0.6934\n",
            "Epoch 4 Batch 200 Loss 0.6606\n",
            "Epoch 4 Batch 300 Loss 0.6985\n",
            "Epoch 4 Loss 0.6662\n",
            "Time taken for 1 epoch 28.31641721725464 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4373\n",
            "Epoch 5 Batch 100 Loss 0.4177\n",
            "Epoch 5 Batch 200 Loss 0.3731\n",
            "Epoch 5 Batch 300 Loss 0.4813\n",
            "Epoch 5 Loss 0.4506\n",
            "Time taken for 1 epoch 28.408619165420532 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2665\n",
            "Epoch 6 Batch 100 Loss 0.3329\n",
            "Epoch 6 Batch 200 Loss 0.2996\n",
            "Epoch 6 Batch 300 Loss 0.3304\n",
            "Epoch 6 Loss 0.3072\n",
            "Time taken for 1 epoch 28.320509910583496 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1667\n",
            "Epoch 7 Batch 100 Loss 0.2290\n",
            "Epoch 7 Batch 200 Loss 0.2285\n",
            "Epoch 7 Batch 300 Loss 0.2483\n",
            "Epoch 7 Loss 0.2172\n",
            "Time taken for 1 epoch 28.231249809265137 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1704\n",
            "Epoch 8 Batch 100 Loss 0.1457\n",
            "Epoch 8 Batch 200 Loss 0.1437\n",
            "Epoch 8 Batch 300 Loss 0.2555\n",
            "Epoch 8 Loss 0.1621\n",
            "Time taken for 1 epoch 28.0746853351593 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1060\n",
            "Epoch 9 Batch 100 Loss 0.1031\n",
            "Epoch 9 Batch 200 Loss 0.1285\n",
            "Epoch 9 Batch 300 Loss 0.1637\n",
            "Epoch 9 Loss 0.1260\n",
            "Time taken for 1 epoch 28.05738377571106 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0751\n",
            "Epoch 10 Batch 100 Loss 0.1077\n",
            "Epoch 10 Batch 200 Loss 0.1021\n",
            "Epoch 10 Batch 300 Loss 0.0864\n",
            "Epoch 10 Loss 0.1007\n",
            "Time taken for 1 epoch 27.997223615646362 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "fG2tvR0doVbE"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "y2CthW6dqbig"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "yyNahKUsq7-6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "cbyaRy6QrT7J",
        "outputId": "2b689310-b9b2-432d-a794-fe83270779c3"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s too cold here . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "-yZ5la-urnEh",
        "outputId": "6bd0a42d-c371-489d-a3b1-ea431820de26"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}